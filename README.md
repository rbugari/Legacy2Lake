# Legacy2Lake ðŸš€ (v1.3 - Contextual Edition)

**Legacy2Lake** is an AI-augmented modernization platform that automates the transition from legacy ETL ecosystems (SSIS, Informatica, SQL) to modern Cloud Lakehouse architectures (Databricks, Snowflake).

## ðŸ§  Core Capabilities (Rel 1.1 - 1.3)
- **Multi-Agent Orchestration**: Specialized agents (Detective, Cartographer, Interpreter, Critic) collaborating to build high-fidelity solutions.
- **Context Injection**: Incorporate "Tribal Knowledge" into the migration loop to generate **Virtual Steps**.
- **Operational Intelligence**: Automated inference of data frequency, load strategies, and PII detection.
- **Design Registry**: Global policy engine to enforce senior-architect standards (naming, paths, security) across the entire codebase.

## ðŸ“– Quick Links
- **[Getting Started: Introduction](docs/INTRODUCTION.md)**
- **[Project Roadmap & Versions](docs/FUTURE_RELEASES.md)**
- **[Phase 1: Triage & Discovery](docs/PHASE_1_TRIAGE.md)**
- **[Phase 3: Refinement & Medallion](docs/PHASE_3_REFINEMENT.md)**

## ðŸ›  Quick Start
To launch the platform locally:
1. Ensure your `.env` is configured with Azure OpenAI and Supabase credentials.
2. Run the unified launcher:
```bash
python run.py
```
3. Access the dashboard at `http://localhost:3005`.

---
*Powered by the Legacy2Lake Orchestration Engine.*
